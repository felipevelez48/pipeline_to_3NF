# Dataâ€¯PipelineÂ Microâ€‘BatchesÂ ğŸ“¦â€¯âœâ€¯3â€¯NFÂ âœâ€¯TestsÂ âœâ€¯Airflow

> **Reto tÃ©cnico â€“ Data Engineer**  
> Ingesta de un un CSV masivo de ofertas de empleo, lo normalizamos en un modelo 3â€¯NF en PostgreSQL y orquestamos el ciclo completo con Dockerâ€¯Composeâ€¯+â€¯Airflow.  IncluÃ­ pruebas de calidad con pytestâ€¯&â€¯pandera y un diseÃ±o conceptual OLAP.

---

## ğŸ“‚Â Estructura del repositorio

```text
.
â”œâ”€â”€ data/                    # âŠ CSV crudo (data_jobs.csv)
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ jobs_ingest_transform_dag.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schema.sql           # DDL 3â€¯NF + Ã­ndices
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingest_raw.py        # carga data_jobs.csv â†’ raw.jobs
â”‚   â””â”€â”€ transform_to_3nf.py  # limpieza + 3â€¯NF
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_schema_raw.py   # Pandera
â”‚   â”œâ”€â”€ test_functions_cleaning.py
â”‚   â””â”€â”€ test_jobs_integrity.py
â”œâ”€â”€ docker-compose.yml       # PostgreSQL 16 + Airflow 2.9
â”œâ”€â”€ pyproject.toml           # Ruff config
â”œâ”€â”€ requirements.txt         # libs extra (ftfy, panderaâ€¦)
â””â”€â”€ README.md                # â† estÃ¡s aquÃ­
```


## âš™ï¸â€¯Requisitos

- Dockerâ€¯&â€¯DockerÂ Compose v2

- Make (opcional) para atajos (make up, make test, â€¦)

- No necesitas instalar nada en tu mÃ¡quina: todo corre en contenedores.

## ğŸš€â€¯Puesta en marcha rÃ¡pida
```bash
# 1) Copia variables de ejemplo y ajusta si quieres
cp .env.example .env.engineer

# 2) Construye imÃ¡genes e inicia servicios (â‰ˆ3â€‘4â€¯min la 1Âª vez)
docker compose up -d --build

# 3) Abre Airflow UI â†’ http://localhost:8080  (admin / admin)
#    Lanza la DAG jobs_ingest_transform (t1_ingest â†’ t2_transform)

# 4) Ejecuta pruebas de calidad
docker compose exec airflow pytest -q
# 8 tests OK  âœ…
```

## ğŸ—„ï¸â€¯Modelo relacional (3â€¯NF)
```bash
companies 1â”€â”
locations 1â”€â”¤
job_titles 1â”¤
schedules 1â”€â”´â”€â”
salary_rates 1â”˜ â”‚
                â”‚   (M:N)  skills
        jobsâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ job_skill

```
- Columnas FK ahora son INTEGER y todas las claves forÃ¡neas se crearon (ver schema.sql).

- Ãndices extra en jobs(location_id) y jobs(company_id) aceleran los JOINs.

## ğŸ§ªâ€¯Tests con pytestâ€¯+â€¯pandera

| Test                             | QuÃ© valida                                              |
| -------------------------------- | ------------------------------------------------------- |
| **test\_schema\_raw\.py**        | El DF crudo respeta tipos y nulos.                      |
| **test\_functions\_cleaning.py** | Unit tests de `fix_encoding`, `clean_location`, etc.    |
| **test\_jobs\_integrity.py**     | *Checks* de FK + conteo de huÃ©rfanos (ahora todo pasa). |

## ğŸ”„â€¯OrquestaciÃ³n (Airflow)

- DAG: dags/jobs_ingest_transform_dag.py

    - t1_ingestâ€¯â†’â€¯lee CSV y llena raw.jobs (microâ€‘batches vÃ­a chunksize=1000).

    - t2_transformâ€¯â†’â€¯normaliza y carga 3â€¯NF (tambiÃ©n en lotes).

- Healthâ€‘check PostgreSQL con pg_isready evita carreras de arranque.

- Logs montados en ./logs para fÃ¡cil inspecciÃ³n.

## ğŸŒŸâ€¯DiseÃ±o Estrella (conceptual)

| Componente                  | DescripciÃ³n                                                     |
| --------------------------- | --------------------------------------------------------------- |
| **Fact** `fact_job_posting` | Grano: 1 oferta. FK: company, title, location, date.            |
| Dimâ€¯empresa                 | sector, tamaÃ±o, HQ.                                             |
| Dimâ€¯ubicaciÃ³n               | ciudad, estado, paÃ­s, lat/long.                                 |
| Dimâ€¯fecha                   | dÃ­a, mes, Q, festivo.                                           |
| Dimâ€¯tÃ­tulo                  | familia (Dataâ€¯Engineer, Analystâ€¦).                              |
| Dimâ€¯skill\*                 | con puente `fact_job_skill` para anÃ¡lisis de skills.            |
| **Medidas**                 | `salary_year_avg`, `salary_hour_avg`, `is_remote`, `days_open`. |

## ğŸ“â€¯Decisiones de diseÃ±oÂ â€”Â Â¿porâ€¯quÃ© asÃ­ y no de otra forma?

| Capa                     | ElecciÃ³n                                                | Â¿Porâ€¯quÃ© la elegimos?                                                                                                                                                                                                                                                   | Alternativas consideradas                                                                                             |
| ------------------------ | ------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **Base de datos OLTP**   | **PostgreSQLâ€¯16 Alpine**                                | - **EstÃ¡ndar deâ€‘facto** en la comunidad de datos, 100â€¯% openâ€‘source.<br>- Soporta JSONB, Ã­ndices GIN y funciones avanzadas que facilitan prototipar sin inventar â€œdataâ€¯lakesâ€ caseros.<br>- Imagen *Alpine*â€¯â†’â€¯\~â€¯70â€¯MB; arranca en segundos y cabe en equipos modestos. | MySQL/MariaDB (sin JSONB nativo), SQLite (monousuario), Cloudâ€‘DB (costo y credenciales)                               |
| **Orquestador**          | **Apacheâ€¯Airflowâ€¯2.9**                                  | - NecesitÃ¡bamos *scheduler*, *retries*, logs y UI; Airflow los trae *outâ€‘ofâ€‘theâ€‘box*.<br>- DAGs como cÃ³digoâ€¯â†’â€¯versionables en Git.<br>- Gran comunidad, fÃ¡cil escalar de dockerâ€‘compose â†’ K8s si el proyecto crece.                                                     | Prefect (muy bueno pero lockâ€‘in licencias), Dagster (curva de aprendizaje + GraphQL), Cron + Bash (pobre visibilidad) |
| **Formato de ingestiÃ³n** | **CSV plano** â†’ tabla `raw.jobs`                        | - Es el formato original del reto.<br>- Pandas carga \~200â€¯MB en <â€¯5â€¯s dentro del contenedor; no valÃ­a complicarse con Parquet.                                                                                                                                         | Parquet/Avro (Ãºtil para particiones, pero overkill en demo)                                                           |
| **Modelo lÃ³gico**        | **3NF + catÃ¡logos** (`companies`,Â `locations`,Â `jobs`â€¦) | - Desnormalizar todo en una sola tabla produce duplicaciÃ³n masiva (10â€¯M+ filas Ã— columnas repetidas).<br>- 3NF reduce tamaÃ±o \~3Ã— y protege integridad con FK.<br>- Facilita construir *Starâ€¯Schema* despuÃ©s (dimensiones ya estÃ¡n).                                    | â€œOne Big Tableâ€, esquema ancho (simple al inicio pero caro y propenso a errores)                                      |
| **Tests de calidad**     | **pytestÂ +Â Pandera**                                    | - pytestâ€¯â†’â€¯framework de facto, compatible con GitHubâ€¯Actions.<br>- Pandera describe *dataframes* como *schemas* declarativos; perfecta para validar DF intermedios y simular â€œdbtâ€¯testâ€ sin dbt.<br>- Se integra con pytest (`@pa.check_types`).                        | Greatâ€¯Expectations (potente pero pesado), dbtâ€¯test (requiere dbt DAG extra), asserts manuales                         |
| **Estilo & Lint**        | **ruff**                                                | - Lint + format en \~50Ã— la velocidad de flake8/black; una sola herramienta.<br>- Se ejecuta en CI en <â€¯5â€¯s.                                                                                                                                                            | flake8 + black + isort (tres pasos), pylint (lento)                                                                   |
| **ContainerizaciÃ³n**     | **dockerâ€‘compose**                                      | - Un solo comando levanta Postgres + Airflow; ideal para revisores.<br>- `_PIP_ADDITIONAL_REQUIREMENTS` instala libs sin construir imagen custom â†’ menos fricciÃ³n al probar.                                                                                            | Build de imagen propia (mÃ¡s limpio en prod), makefile local                                                           |
| **GestiÃ³n de secretos**  | **`.env.engineer`â€¯+â€¯variables Docker**                  | - Nada de credenciales hardcodeadas; los valores reales se inyectan en tiempo de arranque.<br>- Compatible con GitHubâ€¯Secrets si se deploya en Actions.                                                                                                                 | DockerÂ Secrets, HashiCorpÂ Vault (innecesario en demo)                                                                 |


## ğŸ’­ğŸ§ â€¯Retos, decisiones & aprendizajes

- **RAMâ€¯vs.â€¯microâ€‘batches**
    -Procesar ~800â€¯k filas y 12â€¯M registros puente en un portÃ¡til deâ€¯8â€¯GB demostrÃ³ que cargar todo en memoria no escala. OptÃ© por chunksize=1â€¯000 y method="multi" en pandas.to_sql, para enviar lotes pequeÃ±os a Postgres sin reventar la RAM.

- **Tipado flotante accidental**
    - Al volcar DataFrames, to_sql convertÃ­a las claves forÃ¡neas a doubleÂ precision. Los tests de integridad fallaron. SoluciÃ³n: castear con ALTER TABLE â€¦ ALTER COLUMN â€¦ TYPE integer USING â€¦::integerÂ antes de crear las FK, y aÃ±adir un test Pandera que confirme dtype == Int64.

- **Orden correcto: Ã­ndicesÂ y FK**
    - Si creas las FK cuando las columnas aÃºn son floats, luego no puedes castear. El flujo ganador fue: castear âœ limpiar nulos âœ crear Ã­ndices âœ agregar claves forÃ¡neas.

- **Zombie tasks en Airflow**
    - El scheduler marcaba la tarea de transformaciÃ³n como zombie porque insertar millones de filas excedÃ­a elÂ timeout. Al fragmentar la carga con microâ€‘batches y reducir la concurrencia de la DAG, el run se estabilizÃ³ (cada lote <â€¯60â€¯s).

- **Memoria subestimada**
    -AsumÃ­ que el CSV de 220â€¯MB cabÃ­a holgadoâ€¦ y no. Ver la mÃ¡quina intercambiando swap enseÃ±Ã³ que el â€œdemo laptopâ€ no es la referencia; diseÃ±a para que el pipeline (no tu RAM) escale.

- **GitÂ y archivos grandes**
    -Subir ese CSV despertÃ³ el limite de 100â€¯MB de GitHub. Tuve que aprender git filterâ€‘repo, purgar el historial y rehacer el commit. Moraleja: agrega los datos crudos a .gitignore desde el dÃ­aÂ 0 â€”â€¯o usa GitÂ LFS si realmente los necesitas versionados.

- **Airflow localâ€¯â‰ â€¯ProducciÃ³n**
    - _PIP_ADDITIONAL_REQUIREMENTS es prÃ¡ctico para probar dependencias extra (ftfy, ruff, Pandera) pero reinstala paquetes en cada dockerÂ up, lo cual es frÃ¡gil y lento. En producciÃ³n se reemplazarÃ­a por una imagen custom y versionada.

- **Pandera frente a dbt**
    -ElegÃ­ Pandera porque nuestras transformaciones viven en Python y querÃ­amos validar DataFrames antes de llegar a la base. Si la arquitectura migrara a Sparkâ€¯+â€¯Parquet, lo razonable serÃ­a mover las pruebas de calidad a dbtâ€¯Core.

- **Autovacuum y performance**
    - Durante la ingesta masiva notÃ© que autovacuum de Postgres se activaba y alargaba la DAG. En un entorno real, ajustarÃ­amos maintenance_work_mem y autovacuum_naptime, y crearÃ­amos los Ã­ndices despuÃ©s de la carga inicial.

- **Testâ€‘first mindset**
    - Mantener pytest en rojo hasta que cada falla se resuelva guÃ­a el desarrollo. Todos los tests corren en <â€¯10â€¯s, de modo que iterar es rÃ¡pido y seguro.

## â–¶ï¸â€¯CÃ³mo probar otra carga
```bash
# 1. Copia otro CSV grande a data/ y renombra el anterior si no quieres duplicar.
# 2. Lanza nuevamente la DAG desde la UI o por CLI:
docker compose exec airflow airflow dags trigger jobs_ingest_transform
# 3. Reâ€‘ejecuta tests:
docker compose exec airflow pytest -q
```



## ğŸ“ŠğŸ¤– Autor: John Felipe VÃ©lez

### Data Engineer

